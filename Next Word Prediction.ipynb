{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc0dbb6-ee8c-45d8-9bf0-e4c02c2542ef",
   "metadata": {},
   "source": [
    "### Importing all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f27a3c36-5ee1-4474-9c9f-b67b7cff5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e50ca1-d7bd-48d2-b97f-63bf221a43f2",
   "metadata": {},
   "source": [
    "### Reading the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae133f1-f1c9-4b0d-9879-5ac0f0de6a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin. He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections. The bedding was hardly able to cover it and seemed ready to slide off any moment. His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked. \"What\\'s happened to me?\" he thought. It wasn\\'t a dream. His room, a proper human room although a little too small, lay peacefully between its four familiar walls. A collection of textile samples lay spread out on the table - Samsa was a travelling salesman - and above it there hung a picture that he had recently cut out of an illustrated magazine and housed in a nice, gilded frame. It showed a lady fitted out with a fur hat and fur boa who sat upright, raising a heavy fur muff that covered the whole of her lower arm towards t'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"textfile.txt\", \"r\", encoding = \"utf8\")\n",
    "\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "\n",
    "data1 = \"\"\n",
    "for i in lines:\n",
    "  data1 = ' '. join(lines) \n",
    "\n",
    "data1 = data1.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  \n",
    " \n",
    "data1 = data1.split()\n",
    "data1 = ' '.join(data1)\n",
    "data1= data1[:1000]\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2930f8-6e8a-4d6c-ac75-559f85a2ad52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f4854d-0f87-4cf7-854f-97dbeb9724e2",
   "metadata": {},
   "source": [
    "### Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea91d1a9-aa7e-45b3-b7a6-2e3c20a0d9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 22, 23, 24, 12, 25, 26, 27, 28, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data1])\n",
    "\n",
    "pickle.dump(tokenizer, open('tokennizer.pkl', 'wb')) #saving it\n",
    "\n",
    "sequence_data1 = tokenizer.texts_to_sequences([data1])[0]\n",
    "sequence_data1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074ea7f6-8da8-433b-bf6f-02419add9456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b05b5a-c8ad-4ee6-9ede-5993363b45ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f7b514-f458-46b4-84a4-f1bcae81dac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sequences:  182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[21, 22, 23, 24],\n",
       "       [22, 23, 24, 12],\n",
       "       [23, 24, 12, 25],\n",
       "       [24, 12, 25, 26],\n",
       "       [12, 25, 26, 27],\n",
       "       [25, 26, 27, 28],\n",
       "       [26, 27, 28,  2],\n",
       "       [27, 28,  2, 29],\n",
       "       [28,  2, 29, 30],\n",
       "       [ 2, 29, 30, 31]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "\n",
    "for i in range(3, len(sequence_data1)):\n",
    "    words = sequence_data1[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "print(\"Length of sequences: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a98e147-782a-46c3-85f4-05f3136bca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    Y.append(i[3])\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c875aed-bfcc-48f1-8abb-ea2bccbb31b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data1:  [[21 22 23]\n",
      " [22 23 24]\n",
      " [23 24 12]\n",
      " [24 12 25]\n",
      " [12 25 26]\n",
      " [25 26 27]\n",
      " [26 27 28]\n",
      " [27 28  2]\n",
      " [28  2 29]\n",
      " [ 2 29 30]]\n",
      "Responses:  [24 12 25 26 27 28  2 29 30 31]\n"
     ]
    }
   ],
   "source": [
    "print(\"Data1: \", X[:10])\n",
    "print(\"Responses: \", Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba56c1a6-fb65-4183-9e8a-cde735b84727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = to_categorical(Y, num_classes=vocab_size)\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cbaa4-912a-4aa9-b9de-b6a321a53a85",
   "metadata": {},
   "source": [
    "### Model Creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "030967c4-032e-405a-b213-77e725cc01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dca99d8-55a4-4a21-badd-768551c6befc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             1310      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 131)               131131    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13181441 (50.28 MB)\n",
      "Trainable params: 13181441 (50.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c1ddfa8-d642-4264-98e0-59731343ea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "3/3 [==============================] - 4s 269ms/step - loss: 4.8754\n",
      "Epoch 2/70\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 4.8656\n",
      "Epoch 3/70\n",
      "3/3 [==============================] - 1s 267ms/step - loss: 4.8311\n",
      "Epoch 4/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 4.7337\n",
      "Epoch 5/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 4.6872\n",
      "Epoch 6/70\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 4.6330\n",
      "Epoch 7/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 4.6501\n",
      "Epoch 8/70\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 4.6263\n",
      "Epoch 9/70\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 4.5967\n",
      "Epoch 10/70\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 4.5868\n",
      "Epoch 11/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 4.5606\n",
      "Epoch 12/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 4.5366\n",
      "Epoch 13/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 4.5028\n",
      "Epoch 14/70\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 4.4592\n",
      "Epoch 15/70\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 4.3970\n",
      "Epoch 16/70\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 4.3076\n",
      "Epoch 17/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 4.1700\n",
      "Epoch 18/70\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 4.0621\n",
      "Epoch 19/70\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 3.9592\n",
      "Epoch 20/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 3.9084\n",
      "Epoch 21/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 3.8749\n",
      "Epoch 22/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 3.8033\n",
      "Epoch 23/70\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 3.7661\n",
      "Epoch 24/70\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 3.7272\n",
      "Epoch 25/70\n",
      "3/3 [==============================] - 1s 287ms/step - loss: 3.6705\n",
      "Epoch 26/70\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 3.5993\n",
      "Epoch 27/70\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 3.4871\n",
      "Epoch 28/70\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 3.3514\n",
      "Epoch 29/70\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 3.2465\n",
      "Epoch 30/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 3.0980\n",
      "Epoch 31/70\n",
      "3/3 [==============================] - 1s 287ms/step - loss: 3.0146\n",
      "Epoch 32/70\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 2.8972\n",
      "Epoch 33/70\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 2.7272\n",
      "Epoch 34/70\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 2.5870\n",
      "Epoch 35/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 2.5424\n",
      "Epoch 36/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 2.3826\n",
      "Epoch 37/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 2.3500\n",
      "Epoch 38/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 2.1964\n",
      "Epoch 39/70\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 2.0654\n",
      "Epoch 40/70\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 1.9170\n",
      "Epoch 41/70\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 1.8389\n",
      "Epoch 42/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 1.6928\n",
      "Epoch 43/70\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 1.5661\n",
      "Epoch 44/70\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 1.4693\n",
      "Epoch 45/70\n",
      "3/3 [==============================] - 1s 288ms/step - loss: 1.3875\n",
      "Epoch 46/70\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 1.3421\n",
      "Epoch 47/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 1.2074\n",
      "Epoch 48/70\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 1.1523\n",
      "Epoch 49/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 1.2244\n",
      "Epoch 50/70\n",
      "3/3 [==============================] - 1s 293ms/step - loss: 1.3184\n",
      "Epoch 51/70\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 1.2439\n",
      "Epoch 52/70\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 1.1856\n",
      "Epoch 53/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 1.1306\n",
      "Epoch 54/70\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 1.1619\n",
      "Epoch 55/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 1.1951\n",
      "Epoch 56/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 1.1276\n",
      "Epoch 57/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 1.0023\n",
      "Epoch 58/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 1.0268\n",
      "Epoch 59/70\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 0.8891\n",
      "Epoch 60/70\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 0.8457\n",
      "Epoch 61/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 0.7823\n",
      "Epoch 62/70\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 0.6937\n",
      "Epoch 63/70\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.6664\n",
      "Epoch 64/70\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 0.5551\n",
      "Epoch 65/70\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 0.5045\n",
      "Epoch 66/70\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 0.4633\n",
      "Epoch 67/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 0.4141\n",
      "Epoch 68/70\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 0.3564\n",
      "Epoch 69/70\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 0.3158\n",
      "Epoch 70/70\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 0.2638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x170e550e650>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model.fit(X, Y, epochs=70, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fbfd1c9-b2e9-48fc-b2ac-194ac6448894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" We are using the tokenizer and models trained and we are creating the sequence of the text entered and thenusing our model \n",
    "    to predict and return the the predicted word. \n",
    "\"\"\"\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "\n",
    "  sequence = tokenizer.texts_to_sequences([text])\n",
    "  sequence = np.array(sequence)\n",
    "  preds = np.argmax(model.predict(sequence))\n",
    "  predicted_word = \"\"\n",
    "  \n",
    "  for key, value in tokenizer.word_index.items():\n",
    "      if value == preds:\n",
    "          predicted_word = key\n",
    "          break\n",
    "  \n",
    "  print(predicted_word)\n",
    "  return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a7f53e7-9052-41d7-8e2c-5c665b223e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your line:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution completed.....\n"
     ]
    }
   ],
   "source": [
    "# We will run the model until the user decides to stop the script.\n",
    "# While the script is running, we try and check if the prediction can be made on the text. If no prediction can be made we just continue.\n",
    "\n",
    "while(True):\n",
    "  text = input(\"Enter your line: \")\n",
    "  \n",
    "  if text == \"0\":\n",
    "      print(\"Execution completed.....\")\n",
    "      break\n",
    "  \n",
    "  else:\n",
    "      try:\n",
    "          text = text.split(\" \")\n",
    "          text = text[-3:]\n",
    "          print(text)\n",
    "        \n",
    "          Predict_Next_Words(model, tokenizer, text)\n",
    "          \n",
    "      except Exception as e:\n",
    "        print(\"Error occurred: \",e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19005447-b12b-433f-bfe4-3f684b995038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
